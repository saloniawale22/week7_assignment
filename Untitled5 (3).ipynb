{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLimTcQoouxS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_data(directory):\n",
        "    texts = []\n",
        "    labels = []\n",
        "\n",
        "    # Loop through each file in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            label = filename.split('_')[0]  # Assuming labels are in the filename, like 'label_filename.txt'\n",
        "            with open(os.path.join(directory, filename), 'r') as file:\n",
        "                texts.append(file.read())\n",
        "                labels.append(label)\n",
        "\n",
        "    return texts, np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "data_dir = \"/content/drive/MyDrive/Tech400_animals\"\n",
        "texts, labels = load_data(data_dir)"
      ],
      "metadata": {
        "id": "z6QpFv_opEfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    # Remove punctuation and tokenize\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "def build_vocab(texts):\n",
        "    vocabulary = {}\n",
        "    index = 0\n",
        "    for text in texts:\n",
        "        tokens = tokenize(text)\n",
        "        for token in tokens:\n",
        "            if token not in vocabulary:\n",
        "                vocabulary[token] = index\n",
        "                index += 1\n",
        "    return vocabulary\n",
        "\n",
        "def text_to_vector(text, vocabulary):\n",
        "    vector = [0] * len(vocabulary)\n",
        "    tokens = tokenize(text)\n",
        "    for token in tokens:\n",
        "        if token in vocabulary:\n",
        "            index = vocabulary[token]\n",
        "            vector[index] += 1\n",
        "    return vector\n",
        "\n",
        "# Build vocabulary\n",
        "vocabulary = build_vocab(texts)\n",
        "\n",
        "# Convert texts to vectors\n",
        "X = np.array([text_to_vector(text, vocabulary) for text in texts])"
      ],
      "metadata": {
        "id": "Varq8qeNpEbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(labels):\n",
        "    label_to_index = {}\n",
        "    index = 0\n",
        "    encoded_labels = []\n",
        "\n",
        "    for label in labels:\n",
        "        if label not in label_to_index:\n",
        "            label_to_index[label] = index\n",
        "            index += 1\n",
        "        encoded_labels.append(label_to_index[label])\n",
        "\n",
        "    return np.array(encoded_labels), label_to_index\n",
        "\n",
        "# Encode labels\n",
        "y, label_to_index = encode_labels(labels)"
      ],
      "metadata": {
        "id": "Ky7Jb_pgpEYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Initialize weights and bias\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for _ in range(self.epochs):\n",
        "            # Linear model\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            # Apply sigmoid function\n",
        "            y_predicted = self.sigmoid(linear_model)\n",
        "\n",
        "            # Compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.sigmoid(linear_model)\n",
        "        return [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "\n",
        "# Training the model\n",
        "model = LogisticRegression(learning_rate=0.01, epochs=1000)\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "Y-PrfXWkpEUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "# Set average to 'micro', 'macro', 'weighted', or None\n",
        "precision = precision_score(y, y_pred, average='micro')\n",
        "recall = recall_score(y, y_pred, average='micro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIZF1no6pEPl",
        "outputId": "73d6b0ad-a83c-41f6-c571-f2460d6efc8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.05\n",
            "Precision: 0.05\n",
            "Recall: 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTzThGRBpEId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vByeULVapEDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}